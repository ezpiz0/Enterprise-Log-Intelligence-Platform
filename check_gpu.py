"""
=============================================================================
check_gpu.py - –°–∫—Ä–∏–ø—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ GPU
=============================================================================

–≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ CUDA-—Å–æ–≤–º–µ—Å—Ç–∏–º–æ–≥–æ GPU –∏ –≤—ã–≤–æ–¥–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
–æ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞—Ö.

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python check_gpu.py

–ê–≤—Ç–æ—Ä: –ö–æ–º–∞–Ω–¥–∞ Atomichack 3.0
=============================================================================
"""

import sys
import torch
from processing.ml_analysis import get_device

# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º UTF-8 –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è —ç–º–æ–¥–∑–∏ –≤ Windows
if sys.platform == 'win32':
    try:
        sys.stdout.reconfigure(encoding='utf-8')
    except:
        pass


def main():
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å GPU –∏ –≤—ã–≤–æ–¥–∏—Ç –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é.
    """
    print("=" * 80)
    print("üîç –ü–†–û–í–ï–†–ö–ê –î–û–°–¢–£–ü–ù–û–°–¢–ò GPU")
    print("=" * 80)
    print()
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ PyTorch
    print(f"üì¶ –í–µ—Ä—Å–∏—è PyTorch: {torch.__version__}")
    print(f"üîß CUDA –¥–æ—Å—Ç—É–ø–Ω–∞: {'–î–∞ ‚úÖ' if torch.cuda.is_available() else '–ù–µ—Ç ‚ùå'}")
    print()
    
    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
    print("-" * 80)
    print("üéØ –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞:")
    print("-" * 80)
    device = get_device()
    print()
    
    # –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ GPU (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)
    if torch.cuda.is_available():
        print("-" * 80)
        print("üíé –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û GPU:")
        print("-" * 80)
        gpu_count = torch.cuda.device_count()
        print(f"   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ GPU: {gpu_count}")
        print()
        
        for i in range(gpu_count):
            props = torch.cuda.get_device_properties(i)
            print(f"   GPU {i}: {torch.cuda.get_device_name(i)}")
            print(f"      ‚Ä¢ –ü–∞–º—è—Ç—å: {props.total_memory / 1024**3:.2f} GB")
            print(f"      ‚Ä¢ Compute Capability: {props.major}.{props.minor}")
            print(f"      ‚Ä¢ –ú—É–ª—å—Ç–∏–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä—ã: {props.multi_processor_count}")
            print()
        
        # –í–µ—Ä—Å–∏—è CUDA
        print(f"   CUDA –≤–µ—Ä—Å–∏—è: {torch.version.cuda}")
        print(f"   cuDNN –≤–µ—Ä—Å–∏—è: {torch.backends.cudnn.version()}")
        print()
        
        print("=" * 80)
        print("‚úÖ GPU –î–û–°–¢–£–ü–ï–ù! –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –Ω–∞ GPU.")
        print("   –û–∂–∏–¥–∞–µ–º–æ–µ —É—Å–∫–æ—Ä–µ–Ω–∏–µ: 5-10x –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å CPU")
        print("=" * 80)
    else:
        print("-" * 80)
        print("üí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –î–õ–Ø –í–ö–õ–Æ–ß–ï–ù–ò–Ø GPU:")
        print("-" * 80)
        print("   1. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —É –≤–∞—Å –µ—Å—Ç—å NVIDIA GPU")
        print("   2. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –¥—Ä–∞–π–≤–µ—Ä—ã NVIDIA: https://www.nvidia.com/drivers")
        print("   3. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ CUDA Toolkit: https://developer.nvidia.com/cuda-downloads")
        print("   4. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ PyTorch —Å CUDA –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π:")
        print("      pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118")
        print()
        print("=" * 80)
        print("‚ÑπÔ∏è  GPU –ù–ï–î–û–°–¢–£–ü–ï–ù. –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –Ω–∞ CPU.")
        print("   –≠—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ, –Ω–æ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –±—É–¥–µ—Ç –º–µ–¥–ª–µ–Ω–Ω–µ–µ.")
        print("=" * 80)
    
    print()


if __name__ == "__main__":
    main()

