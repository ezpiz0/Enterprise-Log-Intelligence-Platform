"""
=============================================================================
processing/ml_analysis.py - ÐœÐ¾Ð´ÑƒÐ»ÑŒ Ð¼Ð°ÑˆÐ¸Ð½Ð½Ð¾Ð³Ð¾ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð¸ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° ÑÑ…Ð¾Ð¶ÐµÑÑ‚Ð¸
=============================================================================

Ð­Ñ‚Ð¾Ñ‚ Ð¼Ð¾Ð´ÑƒÐ»ÑŒ ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚ Ð»Ð¾Ð³Ð¸ÐºÑƒ Ð¼Ð°ÑˆÐ¸Ð½Ð½Ð¾Ð³Ð¾ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð´Ð»Ñ ÑÐ¾Ð¿Ð¾ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ð¸Ñ Ð»Ð¾Ð³Ð¾Ð²
Ñ Ð±Ð°Ð·Ð¾Ð¹ Ð·Ð½Ð°Ð½Ð¸Ð¹. Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Sentence-BERT Ð´Ð»Ñ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³Ð¾Ð²
(Ð²ÐµÐºÑ‚Ð¾Ñ€Ð½Ñ‹Ñ… Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ð¸Ð¹) Ñ‚ÐµÐºÑÑ‚Ð¾Ð² Ð¸ Ð²Ñ‹Ñ‡Ð¸ÑÐ»ÐµÐ½Ð¸Ñ ÐºÐ¾ÑÐ¸Ð½ÑƒÑÐ½Ð¾Ð¹ ÑÑ…Ð¾Ð¶ÐµÑÑ‚Ð¸ Ð¼ÐµÐ¶Ð´Ñƒ Ð½Ð¸Ð¼Ð¸.

ÐžÑÐ½Ð¾Ð²Ð½Ð°Ñ Ð¸Ð´ÐµÑ Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼Ð°:
1. ERROR-Ð»Ð¾Ð³Ð¸ ÑÐ¾Ð¿Ð¾ÑÑ‚Ð°Ð²Ð»ÑÑŽÑ‚ÑÑ Ñ Ð¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ð¼Ð¸ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð°Ð¼Ð¸
2. WARNING-Ð»Ð¾Ð³Ð¸ ÑÐ¾Ð¿Ð¾ÑÑ‚Ð°Ð²Ð»ÑÑŽÑ‚ÑÑ Ñ Ð¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ð¼Ð¸ Ð°Ð½Ð¾Ð¼Ð°Ð»Ð¸ÑÐ¼Ð¸ Ð² ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð½Ñ‹Ñ… Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼
3. "ÐžÑÐ¸Ñ€Ð¾Ñ‚ÐµÐ²ÑˆÐ¸Ðµ" WARNING-Ð»Ð¾Ð³Ð¸ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÑÑŽÑ‚ÑÑ Ð¿Ñ€Ð¾Ñ‚Ð¸Ð² Ð²ÑÐµÐ¹ Ð±Ð°Ð·Ñ‹ Ð°Ð½Ð¾Ð¼Ð°Ð»Ð¸Ð¹

ÐÐ²Ñ‚Ð¾Ñ€: ÐšÐ¾Ð¼Ð°Ð½Ð´Ð° Atomichack 3.0
=============================================================================
"""

import numpy as np
import torch
from sentence_transformers import util
import pandas as pd
import sys

from config import ERROR_SIMILARITY_THRESHOLD, WARNING_SIMILARITY_THRESHOLD


# =============================================================================
# Ð‘Ð•Ð—ÐžÐŸÐÐ¡ÐÐÐ¯ ÐŸÐ•Ð§ÐÐ¢Ð¬ (Ð´Ð»Ñ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ¸ Ð²ÑÐµÑ… ÐºÐ¾Ð´Ð¸Ñ€Ð¾Ð²Ð¾Ðº)
# =============================================================================

def safe_print(*args, **kwargs):
    """
    Ð‘ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð°Ñ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ñ Ð¿ÐµÑ‡Ð°Ñ‚Ð¸, ÐºÐ¾Ñ‚Ð¾Ñ€Ð°Ñ Ð¾Ð±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÑ‚ Ð¾ÑˆÐ¸Ð±ÐºÐ¸ ÐºÐ¾Ð´Ð¸Ñ€Ð¾Ð²ÐºÐ¸.
    Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ Ð´Ð»Ñ Ð²Ñ‹Ð²Ð¾Ð´Ð° ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹ Ñ ÑÐ¼Ð¾Ð´Ð·Ð¸ Ð² Windows ÐºÐ¾Ð½ÑÐ¾Ð»ÑŒ.
    """
    try:
        print(*args, **kwargs)
    except UnicodeEncodeError:
        # Ð—Ð°Ð¼ÐµÐ½ÑÐµÐ¼ ÑÐ¼Ð¾Ð´Ð·Ð¸ Ð½Ð° Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ñ‹Ðµ Ð¼ÐµÑ‚ÐºÐ¸
        message = ' '.join(str(arg) for arg in args)
        message = message.replace('ðŸš€', '[GPU]').replace('âš ï¸', '[WARNING]')
        print(message, **kwargs)


# =============================================================================
# ÐžÐŸÐ Ð•Ð”Ð•Ð›Ð•ÐÐ˜Ð• Ð£Ð¡Ð¢Ð ÐžÐ™Ð¡Ð¢Ð’Ð (GPU/CPU)
# =============================================================================

def get_device():
    """
    ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÑ‚ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ðµ ÑƒÑÑ‚Ñ€Ð¾Ð¹ÑÑ‚Ð²Ð¾ Ð´Ð»Ñ Ð²Ñ‹Ñ‡Ð¸ÑÐ»ÐµÐ½Ð¸Ð¹ (GPU Ð¸Ð»Ð¸ CPU).
    
    Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÑÐµÑ‚ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾ÑÑ‚ÑŒ CUDA (NVIDIA GPU) Ð¸ Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ ÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²ÑƒÑŽÑ‰ÐµÐµ
    ÑƒÑÑ‚Ñ€Ð¾Ð¹ÑÑ‚Ð²Ð¾ PyTorch. Ð•ÑÐ»Ð¸ GPU Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½, Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ CPU.
    
    Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚:
        torch.device: Ð£ÑÑ‚Ñ€Ð¾Ð¹ÑÑ‚Ð²Ð¾ Ð´Ð»Ñ Ð²Ñ‹Ñ‡Ð¸ÑÐ»ÐµÐ½Ð¸Ð¹ ('cuda' Ð¸Ð»Ð¸ 'cpu')
    
    ÐŸÑ€Ð¸Ð¼ÐµÑ‡Ð°Ð½Ð¸Ñ:
        - ÐŸÑ€Ð¸ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ð¸ GPU Ð²Ñ‹Ð²Ð¾Ð´Ð¸Ñ‚ÑÑ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ Ð¾ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð²Ð¸Ð´ÐµÐ¾ÐºÐ°Ñ€Ñ‚Ñ‹
        - ÐŸÑ€Ð¸ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ð¸ CPU Ð²Ñ‹Ð²Ð¾Ð´Ð¸Ñ‚ÑÑ ÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²ÑƒÑŽÑ‰ÐµÐµ Ð¿Ñ€ÐµÐ´ÑƒÐ¿Ñ€ÐµÐ¶Ð´ÐµÐ½Ð¸Ðµ
        - Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð±ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð° Ð´Ð»Ñ Ð²Ñ‹Ð·Ð¾Ð²Ð° Ð² Ð»ÑŽÐ±Ð¾Ð¹ Ð¼Ð¾Ð¼ÐµÐ½Ñ‚ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸
    """
    if torch.cuda.is_available():
        device = torch.device('cuda')
        gpu_name = torch.cuda.get_device_name(0)
        safe_print(f"ðŸš€ Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ GPU: {gpu_name}")
        safe_print(f"   Ð”Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð°Ñ Ð¿Ð°Ð¼ÑÑ‚ÑŒ: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB")
    else:
        device = torch.device('cpu')
        safe_print("âš ï¸  GPU Ð½Ðµ Ð¾Ð±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½, Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ CPU (Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð±ÑƒÐ´ÐµÑ‚ Ð¼ÐµÐ´Ð»ÐµÐ½Ð½ÐµÐµ)")
    return device


# =============================================================================
# Ð¤Ð£ÐÐšÐ¦Ð˜Ð˜ ÐœÐÐ¨Ð˜ÐÐÐžÐ“Ðž ÐžÐ‘Ð£Ð§Ð•ÐÐ˜Ð¯
# =============================================================================

def find_best_match_sbert_batch(query_embeddings: torch.Tensor, 
                               corpus_embeddings: torch.Tensor, 
                               batch_size: int = 32) -> tuple[np.ndarray, np.ndarray]:
    """
    ÐÐ°Ñ…Ð¾Ð´Ð¸Ñ‚ Ð½Ð°Ð¸Ð±Ð¾Ð»ÐµÐµ Ð¿Ð¾Ñ…Ð¾Ð¶Ð¸Ðµ Ð·Ð°Ð¿Ð¸ÑÐ¸ Ð¸Ð· Ð±Ð°Ð·Ñ‹ Ð·Ð½Ð°Ð½Ð¸Ð¹ Ð´Ð»Ñ ÐºÐ°Ð¶Ð´Ð¾Ð³Ð¾ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°.
    
    Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ ÐºÐ¾ÑÐ¸Ð½ÑƒÑÐ½ÑƒÑŽ ÑÑ…Ð¾Ð¶ÐµÑÑ‚ÑŒ Ð´Ð»Ñ ÑÐ¾Ð¿Ð¾ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ð¸Ñ ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³Ð¾Ð² Ð»Ð¾Ð³Ð¾Ð²
    Ñ ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³Ð°Ð¼Ð¸ Ð¸Ð· Ð±Ð°Ð·Ñ‹ Ð·Ð½Ð°Ð½Ð¸Ð¹. ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÑÐµÑ‚ÑÑ Ð±Ð°Ñ‚Ñ‡Ð°Ð¼Ð¸ Ð´Ð»Ñ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ð¸
    Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ñ Ð¿Ð°Ð¼ÑÑ‚Ð¸.
    
    ÐŸÐ°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹:
        query_embeddings (torch.Tensor): Ð¢ÐµÐ½Ð·Ð¾Ñ€ ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³Ð¾Ð² Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð² (Ð»Ð¾Ð³Ð¾Ð²)
                                         Ð Ð°Ð·Ð¼ÐµÑ€: [N, embedding_dim]
        corpus_embeddings (torch.Tensor): Ð¢ÐµÐ½Ð·Ð¾Ñ€ ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³Ð¾Ð² Ð±Ð°Ð·Ñ‹ Ð·Ð½Ð°Ð½Ð¸Ð¹
                                          Ð Ð°Ð·Ð¼ÐµÑ€: [M, embedding_dim]
        batch_size (int): Ð Ð°Ð·Ð¼ÐµÑ€ Ð±Ð°Ñ‚Ñ‡Ð° Ð´Ð»Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ (Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ 32)
    
    Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚:
        tuple[np.ndarray, np.ndarray]: ÐšÐ¾Ñ€Ñ‚ÐµÐ¶ Ð¸Ð· Ð´Ð²ÑƒÑ… Ð¼Ð°ÑÑÐ¸Ð²Ð¾Ð²:
            - indices: Ð¸Ð½Ð´ÐµÐºÑÑ‹ Ð»ÑƒÑ‡ÑˆÐ¸Ñ… ÑÐ¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ð¹ Ð² corpus_embeddings (Ñ€Ð°Ð·Ð¼ÐµÑ€ N)
            - scores: Ð¾Ñ†ÐµÐ½ÐºÐ¸ ÑÑ…Ð¾Ð¶ÐµÑÑ‚Ð¸ (ÐºÐ¾ÑÐ¸Ð½ÑƒÑÐ½Ð¾Ðµ Ñ€Ð°ÑÑÑ‚Ð¾ÑÐ½Ð¸Ðµ) (Ñ€Ð°Ð·Ð¼ÐµÑ€ N)
        
        Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ð¿ÑƒÑÑ‚Ñ‹Ðµ Ð¼Ð°ÑÑÐ¸Ð²Ñ‹, ÐµÑÐ»Ð¸ Ð²Ñ…Ð¾Ð´Ð½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð½ÐµÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ñ‹.
    
    ÐÐ»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼:
        1. ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÑ‚ Ð²Ð°Ð»Ð¸Ð´Ð½Ð¾ÑÑ‚ÑŒ Ð²Ñ…Ð¾Ð´Ð½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…
        2. ÐžÐ±ÐµÑÐ¿ÐµÑ‡Ð¸Ð²Ð°ÐµÑ‚ Ð¾Ð´Ð¸Ð½Ð°ÐºÐ¾Ð²Ð¾Ðµ ÑƒÑÑ‚Ñ€Ð¾Ð¹ÑÑ‚Ð²Ð¾ (CPU/GPU) Ð´Ð»Ñ Ñ‚ÐµÐ½Ð·Ð¾Ñ€Ð¾Ð²
        3. ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÑ‚ Ð·Ð°Ð¿Ñ€Ð¾ÑÑ‹ Ð±Ð°Ñ‚Ñ‡Ð°Ð¼Ð¸
        4. Ð”Ð»Ñ ÐºÐ°Ð¶Ð´Ð¾Ð³Ð¾ Ð±Ð°Ñ‚Ñ‡Ð° Ð²Ñ‹Ñ‡Ð¸ÑÐ»ÑÐµÑ‚ ÐºÐ¾ÑÐ¸Ð½ÑƒÑÐ½ÑƒÑŽ ÑÑ…Ð¾Ð¶ÐµÑÑ‚ÑŒ ÑÐ¾ Ð²ÑÐµÐ¼ ÐºÐ¾Ñ€Ð¿ÑƒÑÐ¾Ð¼
        5. Ð’Ñ‹Ð±Ð¸Ñ€Ð°ÐµÑ‚ top-1 (Ð»ÑƒÑ‡ÑˆÐµÐµ) ÑÐ¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ðµ Ð´Ð»Ñ ÐºÐ°Ð¶Ð´Ð¾Ð³Ð¾ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°
        6. Ð¡Ð¾Ð±Ð¸Ñ€Ð°ÐµÑ‚ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð²ÑÐµÑ… Ð±Ð°Ñ‚Ñ‡ÐµÐ¹
    
    ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð¾ÑˆÐ¸Ð±Ð¾Ðº:
        - Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ð¿ÑƒÑÑ‚Ñ‹Ðµ Ð¼Ð°ÑÑÐ¸Ð²Ñ‹ Ð¿Ñ€Ð¸ Ð¾ÑˆÐ¸Ð±ÐºÐ°Ñ…
        - Ð’Ñ‹Ð²Ð¾Ð´Ð¸Ñ‚ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ Ð¾Ð± Ð¾ÑˆÐ¸Ð±ÐºÐµ Ð² ÐºÐ¾Ð½ÑÐ¾Ð»ÑŒ
    """
    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð²Ð°Ð»Ð¸Ð´Ð½Ð¾ÑÑ‚ÑŒ Ð²Ñ…Ð¾Ð´Ð½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…
    if (query_embeddings is None or len(query_embeddings) == 0 or 
        corpus_embeddings is None or len(corpus_embeddings) == 0):
        return np.array([]), np.array([])
    
    # ÐŸÐµÑ€ÐµÐ½Ð¾ÑÐ¸Ð¼ Ñ‚ÐµÐ½Ð·Ð¾Ñ€Ñ‹ Ð½Ð° Ð¾Ð´Ð½Ð¾ ÑƒÑÑ‚Ñ€Ð¾Ð¹ÑÑ‚Ð²Ð¾ (CPU/GPU), ÐµÑÐ»Ð¸ Ð¾Ð½Ð¸ Ñ€Ð°Ð·Ð»Ð¸Ñ‡Ð°ÑŽÑ‚ÑÑ
    if query_embeddings.device != corpus_embeddings.device:
        corpus_embeddings = corpus_embeddings.to(query_embeddings.device)
    
    all_indices = []
    all_scores = []
    
    try:
        # ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ Ð·Ð°Ð¿Ñ€Ð¾ÑÑ‹ Ð±Ð°Ñ‚Ñ‡Ð°Ð¼Ð¸ Ð´Ð»Ñ ÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¾Ð³Ð¾ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ñ Ð¿Ð°Ð¼ÑÑ‚Ð¸
        for i in range(0, len(query_embeddings), batch_size):
            # Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÐ¼ Ð±Ð°Ñ‚Ñ‡ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð²
            batch_query_embeddings = query_embeddings[i:i + batch_size]
            
            # Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÑÐµÐ¼ ÐºÐ¾ÑÐ¸Ð½ÑƒÑÐ½ÑƒÑŽ ÑÑ…Ð¾Ð¶ÐµÑÑ‚ÑŒ Ð¼ÐµÐ¶Ð´Ñƒ Ð±Ð°Ñ‚Ñ‡ÐµÐ¼ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð² Ð¸ Ð²ÑÐµÐ¼ ÐºÐ¾Ñ€Ð¿ÑƒÑÐ¾Ð¼
            # Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚: Ð¼Ð°Ñ‚Ñ€Ð¸Ñ†Ð° [batch_size, corpus_size]
            cos_scores = util.pytorch_cos_sim(batch_query_embeddings, corpus_embeddings)
            
            # Ð”Ð»Ñ ÐºÐ°Ð¶Ð´Ð¾Ð³Ð¾ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ° Ð½Ð°Ñ…Ð¾Ð´Ð¸Ð¼ Ð½Ð°Ð¸Ð±Ð¾Ð»ÐµÐµ Ð¿Ð¾Ñ…Ð¾Ð¶ÑƒÑŽ Ð·Ð°Ð¿Ð¸ÑÑŒ (top-1)
            top_results = torch.topk(cos_scores, k=1, dim=-1)
            
            # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð¸Ð½Ð´ÐµÐºÑÑ‹ Ð¸ Ð¾Ñ†ÐµÐ½ÐºÐ¸, Ð¿ÐµÑ€ÐµÐ²Ð¾Ð´Ñ Ð² numpy Ð¼Ð°ÑÑÐ¸Ð²Ñ‹
            all_indices.extend(top_results.indices.flatten().cpu().numpy())
            all_scores.extend(top_results.values.flatten().cpu().numpy())
    
    except Exception as e:
        print(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð²Ð¾ Ð²Ñ€ÐµÐ¼Ñ Ñ€Ð°ÑÑ‡ÐµÑ‚Ð° ÑÑ…Ð¾Ð¶ÐµÑÑ‚Ð¸ SBERT: {e}")
        return np.array([]), np.array([])
    
    return np.array(all_indices), np.array(all_scores)


def run_analysis_pipeline(logs_df: pd.DataFrame, 
                         anomalies_kb: pd.DataFrame, 
                         problems_kb: pd.DataFrame, 
                         model, 
                         case_name: str,
                         anomalies_kb_embeddings: torch.Tensor, 
                         problems_kb_embeddings: torch.Tensor,
                         device = None) -> pd.DataFrame:
    """
    Ð’Ñ‹Ð¿Ð¾Ð»Ð½ÑÐµÑ‚ Ð¿Ð¾Ð»Ð½Ñ‹Ð¹ Ð¿Ð°Ð¹Ð¿Ð»Ð°Ð¹Ð½ ML-Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð´Ð»Ñ ÐºÐ»Ð°ÑÑÐ¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ð¸ Ð»Ð¾Ð³Ð¾Ð².
    
    Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ñ€ÐµÐ°Ð»Ð¸Ð·ÑƒÐµÑ‚ Ñ‚Ñ€ÐµÑ…ÑÑ‚Ð°Ð¿Ð½Ñ‹Ð¹ Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼ ÑÐ¾Ð¿Ð¾ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ð¸Ñ:
    
    Ð­Ñ‚Ð°Ð¿ 1 - ÐšÐ»Ð°ÑÑÐ¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ñ ERROR-Ð»Ð¾Ð³Ð¾Ð²:
        - Ð¡Ð¾Ð¿Ð¾ÑÑ‚Ð°Ð²Ð»ÑÐµÑ‚ ERROR-Ð»Ð¾Ð³Ð¸ Ñ Ð¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ð¼Ð¸ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð°Ð¼Ð¸ Ð¸Ð· Ð±Ð°Ð·Ñ‹ Ð·Ð½Ð°Ð½Ð¸Ð¹
        - Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ Ð¿Ð¾Ñ€Ð¾Ð³ ERROR_SIMILARITY_THRESHOLD
        - Ð¡Ð¾Ð·Ð´Ð°ÐµÑ‚ ÑÐ¿Ð¸ÑÐ¾Ðº "Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ñ… Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼" Ð´Ð»Ñ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð½Ð¾Ð³Ð¾ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° WARNING
    
    Ð­Ñ‚Ð°Ð¿ 2 - ÐšÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð½Ð°Ñ ÐºÐ»Ð°ÑÑÐ¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ñ WARNING-Ð»Ð¾Ð³Ð¾Ð²:
        - Ð¡Ð¾Ð¿Ð¾ÑÑ‚Ð°Ð²Ð»ÑÐµÑ‚ WARNING-Ð»Ð¾Ð³Ð¸ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ñ Ð°Ð½Ð¾Ð¼Ð°Ð»Ð¸ÑÐ¼Ð¸, ÑÐ²ÑÐ·Ð°Ð½Ð½Ñ‹Ð¼Ð¸ Ñ Ð½Ð°Ð¹Ð´ÐµÐ½Ð½Ñ‹Ð¼Ð¸ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð°Ð¼Ð¸
        - Ð­Ñ‚Ð¾ Ð¿Ð¾Ð²Ñ‹ÑˆÐ°ÐµÑ‚ Ñ‚Ð¾Ñ‡Ð½Ð¾ÑÑ‚ÑŒ, Ñ‚Ð°Ðº ÐºÐ°Ðº Ð°Ð½Ð¾Ð¼Ð°Ð»Ð¸Ð¸ Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÑŽÑ‚ÑÑ Ð² ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ðµ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼
        - Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ Ð¿Ð¾Ñ€Ð¾Ð³ WARNING_SIMILARITY_THRESHOLD
    
    Ð­Ñ‚Ð°Ð¿ 3 - Ð“Ð»Ð¾Ð±Ð°Ð»ÑŒÐ½Ð°Ñ ÐºÐ»Ð°ÑÑÐ¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ñ Ð¾ÑÑ‚Ð°Ð²ÑˆÐ¸Ñ…ÑÑ WARNING-Ð»Ð¾Ð³Ð¾Ð²:
        - ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÑ‚ "Ð¾ÑÐ¸Ñ€Ð¾Ñ‚ÐµÐ²ÑˆÐ¸Ðµ" WARNING, Ð½Ðµ ÑÐ²ÑÐ·Ð°Ð½Ð½Ñ‹Ðµ Ñ Ð¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ð¼Ð¸ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð°Ð¼Ð¸
        - Ð¡Ð¾Ð¿Ð¾ÑÑ‚Ð°Ð²Ð»ÑÐµÑ‚ Ð¸Ñ… ÑÐ¾ Ð²ÑÐµÐ¹ Ð±Ð°Ð·Ð¾Ð¹ Ð°Ð½Ð¾Ð¼Ð°Ð»Ð¸Ð¹
        - ÐŸÐ¾Ð¼Ð¾Ð³Ð°ÐµÑ‚ Ð¾Ð±Ð½Ð°Ñ€ÑƒÐ¶Ð¸Ñ‚ÑŒ Ð½Ð¾Ð²Ñ‹Ðµ Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½Ñ‹
    
    ÐŸÐ°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹:
        logs_df (pd.DataFrame): DataFrame Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð½Ñ‹Ð¼Ð¸ Ð»Ð¾Ð³Ð°Ð¼Ð¸
        anomalies_kb (pd.DataFrame): Ð‘Ð°Ð·Ð° Ð·Ð½Ð°Ð½Ð¸Ð¹ Ð°Ð½Ð¾Ð¼Ð°Ð»Ð¸Ð¹
        problems_kb (pd.DataFrame): Ð‘Ð°Ð·Ð° Ð·Ð½Ð°Ð½Ð¸Ð¹ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼
        model: ÐœÐ¾Ð´ÐµÐ»ÑŒ SentenceTransformer Ð´Ð»Ñ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³Ð¾Ð²
        case_name (str): ÐÐ°Ð·Ð²Ð°Ð½Ð¸Ðµ ÑÑ†ÐµÐ½Ð°Ñ€Ð¸Ñ (Ð´Ð»Ñ Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ)
        anomalies_kb_embeddings (torch.Tensor): ÐŸÑ€ÐµÐ´Ð²Ñ‹Ñ‡Ð¸ÑÐ»ÐµÐ½Ð½Ñ‹Ðµ ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³Ð¸ Ð°Ð½Ð¾Ð¼Ð°Ð»Ð¸Ð¹
        problems_kb_embeddings (torch.Tensor): ÐŸÑ€ÐµÐ´Ð²Ñ‹Ñ‡Ð¸ÑÐ»ÐµÐ½Ð½Ñ‹Ðµ ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³Ð¸ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼
        device (torch.device, optional): Ð£ÑÑ‚Ñ€Ð¾Ð¹ÑÑ‚Ð²Ð¾ Ð´Ð»Ñ Ð²Ñ‹Ñ‡Ð¸ÑÐ»ÐµÐ½Ð¸Ð¹ (GPU/CPU)
    
    Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚:
        pd.DataFrame: Ð Ð°ÑÑˆÐ¸Ñ€ÐµÐ½Ð½Ñ‹Ð¹ DataFrame Ñ Ð´Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¼Ð¸ ÐºÐ¾Ð»Ð¾Ð½ÐºÐ°Ð¼Ð¸:
            - final_problem_id (int): ID Ð½Ð°Ð¹Ð´ÐµÐ½Ð½Ð¾Ð¹ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹ (0 ÐµÑÐ»Ð¸ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð°)
            - final_anomaly_id (int): ID Ð½Ð°Ð¹Ð´ÐµÐ½Ð½Ð¾Ð¹ Ð°Ð½Ð¾Ð¼Ð°Ð»Ð¸Ð¸ (0 ÐµÑÐ»Ð¸ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð°)
            - match_score (float): ÐžÑ†ÐµÐ½ÐºÐ° ÑÑ…Ð¾Ð¶ÐµÑÑ‚Ð¸ (Ð¾Ñ‚ 0.0 Ð´Ð¾ 1.0)
    
    ÐžÐ¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ð¸:
        - Ð‘Ð°Ñ‚Ñ‡ÐµÐ²Ð°Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð²ÑÐµÑ… Ð»Ð¾Ð³Ð¾Ð² Ð¾Ð´Ð½Ð¾Ð³Ð¾ Ñ‚Ð¸Ð¿Ð° Ð¾Ð´Ð½Ð¾Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ð¾
        - Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¿Ñ€ÐµÐ´Ð²Ñ‹Ñ‡Ð¸ÑÐ»ÐµÐ½Ð½Ñ‹Ñ… ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³Ð¾Ð² Ð±Ð°Ð·Ñ‹ Ð·Ð½Ð°Ð½Ð¸Ð¹
        - ÐšÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð½Ð°Ñ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð°Ñ†Ð¸Ñ Ð´Ð»Ñ WARNING-Ð»Ð¾Ð³Ð¾Ð²
    """
    # Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ Ð½Ð¾Ð²Ñ‹Ðµ ÐºÐ¾Ð»Ð¾Ð½ÐºÐ¸ Ð½ÑƒÐ»ÐµÐ²Ñ‹Ð¼Ð¸ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸ÑÐ¼Ð¸
    logs_df['final_problem_id'] = 0
    logs_df['final_anomaly_id'] = 0
    logs_df['match_score'] = 0.0
    
    # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ ÑƒÑÑ‚Ñ€Ð¾Ð¹ÑÑ‚Ð²Ð¾ Ð¸Ð· Ð¿Ñ€ÐµÐ´Ð²Ñ‹Ñ‡Ð¸ÑÐ»ÐµÐ½Ð½Ñ‹Ñ… ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³Ð¾Ð², ÐµÑÐ»Ð¸ device Ð½Ðµ Ð¿ÐµÑ€ÐµÐ´Ð°Ð½
    if device is None and problems_kb_embeddings is not None:
        device = problems_kb_embeddings.device
    
    # =========================================================================
    # Ð­Ð¢ÐÐŸ 1: ÐšÐ›ÐÐ¡Ð¡Ð˜Ð¤Ð˜ÐšÐÐ¦Ð˜Ð¯ ERROR-Ð›ÐžÐ“ÐžÐ’
    # =========================================================================
    
    error_mask = logs_df['Level'] == 'ERROR'
    active_problem_ids = []  # Ð¡Ð¿Ð¸ÑÐ¾Ðº Ð½Ð°Ð¹Ð´ÐµÐ½Ð½Ñ‹Ñ… ID Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼
    
    if error_mask.any():
        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³Ð¸ Ð´Ð»Ñ Ð²ÑÐµÑ… ERROR-Ð»Ð¾Ð³Ð¾Ð² Ð¾Ð´Ð½Ð¾Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ð¾ (Ð±Ð°Ñ‚Ñ‡ÐµÐ²Ð°Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ°)
        # ÐœÐ¾Ð´ÐµÐ»ÑŒ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ ÑƒÑÑ‚Ñ€Ð¾Ð¹ÑÑ‚Ð²Ð¾, Ð½Ð° ÐºÐ¾Ñ‚Ð¾Ñ€Ð¾Ðµ Ð±Ñ‹Ð»Ð° Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð°
        error_embeddings = model.encode(
            logs_df.loc[error_mask, 'Generalized_Message'].tolist(), 
            convert_to_tensor=True
        )
        
        # ÐÐ°Ñ…Ð¾Ð´Ð¸Ð¼ Ð½Ð°Ð¸Ð±Ð¾Ð»ÐµÐµ Ð¿Ð¾Ñ…Ð¾Ð¶Ð¸Ðµ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹ Ð´Ð»Ñ ÐºÐ°Ð¶Ð´Ð¾Ð³Ð¾ ERROR
        best_indices, scores = find_best_match_sbert_batch(
            error_embeddings, 
            problems_kb_embeddings
        )
        
        if len(best_indices) > 0:
            error_indices = logs_df.index[error_mask]
            
            # ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ ÐºÐ°Ð¶Ð´Ñ‹Ð¹ ERROR
            for i in range(len(error_indices)):
                # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð¾Ñ†ÐµÐ½ÐºÑƒ ÑÑ…Ð¾Ð¶ÐµÑÑ‚Ð¸
                logs_df.loc[error_indices[i], 'match_score'] = scores[i]
                
                # Ð•ÑÐ»Ð¸ ÑÑ…Ð¾Ð¶ÐµÑÑ‚ÑŒ Ð²Ñ‹ÑˆÐµ Ð¿Ð¾Ñ€Ð¾Ð³Ð°, ÑÑ‡Ð¸Ñ‚Ð°ÐµÐ¼ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñƒ Ð½Ð°Ð¹Ð´ÐµÐ½Ð½Ð¾Ð¹
                if scores[i] >= ERROR_SIMILARITY_THRESHOLD:
                    problem_id = problems_kb.iloc[best_indices[i]]['problem_id']
                    logs_df.loc[error_indices[i], 'final_problem_id'] = problem_id
                    
                    # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð² ÑÐ¿Ð¸ÑÐ¾Ðº Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ñ… Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼ (Ð±ÐµÐ· Ð´ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ‚Ð¾Ð²)
                    if problem_id not in active_problem_ids:
                        active_problem_ids.append(problem_id)
    
    # =========================================================================
    # Ð­Ð¢ÐÐŸ 2: ÐšÐžÐÐ¢Ð•ÐšÐ¡Ð¢ÐÐÐ¯ ÐšÐ›ÐÐ¡Ð¡Ð˜Ð¤Ð˜ÐšÐÐ¦Ð˜Ð¯ WARNING-Ð›ÐžÐ“ÐžÐ’
    # =========================================================================
    
    warning_mask = logs_df['Level'] == 'WARNING'
    
    # ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ WARNING Ñ‚Ð¾Ð»ÑŒÐºÐ¾ ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ðµ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹
    if warning_mask.any() and active_problem_ids:
        # Ð¤Ð¸Ð»ÑŒÑ‚Ñ€ÑƒÐµÐ¼ Ð±Ð°Ð·Ñƒ Ð°Ð½Ð¾Ð¼Ð°Ð»Ð¸Ð¹ Ð¿Ð¾ Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ð¼ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð°Ð¼ (ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð½Ð°Ñ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð°Ñ†Ð¸Ñ)
        context_kb = anomalies_kb[
            anomalies_kb['problem_id'].isin(active_problem_ids)
        ].copy()
        
        if not context_kb.empty:
            # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð¸Ð½Ð´ÐµÐºÑÑ‹ Ð¾Ñ‚Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ñ… Ð°Ð½Ð¾Ð¼Ð°Ð»Ð¸Ð¹ Ð² Ð¸ÑÑ…Ð¾Ð´Ð½Ð¾Ð¹ Ð±Ð°Ð·Ðµ
            context_kb_indices = context_kb.index.to_numpy()
            
            # Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÐ¼ ÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ðµ ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³Ð¸
            context_embeddings = anomalies_kb_embeddings[context_kb_indices]
            
            # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³Ð¸ Ð´Ð»Ñ Ð²ÑÐµÑ… WARNING-Ð»Ð¾Ð³Ð¾Ð²
            warning_embeddings = model.encode(
                logs_df.loc[warning_mask, 'Generalized_Message'].tolist(),
                convert_to_tensor=True
            )
            
            # ÐÐ°Ñ…Ð¾Ð´Ð¸Ð¼ Ð½Ð°Ð¸Ð±Ð¾Ð»ÐµÐµ Ð¿Ð¾Ñ…Ð¾Ð¶Ð¸Ðµ Ð°Ð½Ð¾Ð¼Ð°Ð»Ð¸Ð¸ Ð² ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ðµ
            best_indices_in_context, scores = find_best_match_sbert_batch(
                warning_embeddings, 
                context_embeddings
            )
            
            if len(best_indices_in_context) > 0:
                warning_indices = logs_df.index[warning_mask]
                
                # ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ ÐºÐ°Ð¶Ð´Ñ‹Ð¹ WARNING
                for i in range(len(warning_indices)):
                    # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð¾Ñ†ÐµÐ½ÐºÑƒ ÑÑ…Ð¾Ð¶ÐµÑÑ‚Ð¸
                    logs_df.loc[warning_indices[i], 'match_score'] = scores[i]
                    
                    # Ð•ÑÐ»Ð¸ ÑÑ…Ð¾Ð¶ÐµÑÑ‚ÑŒ Ð²Ñ‹ÑˆÐµ Ð¿Ð¾Ñ€Ð¾Ð³Ð°, ÑÑ‡Ð¸Ñ‚Ð°ÐµÐ¼ Ð°Ð½Ð¾Ð¼Ð°Ð»Ð¸ÑŽ Ð½Ð°Ð¹Ð´ÐµÐ½Ð½Ð¾Ð¹
                    if scores[i] >= WARNING_SIMILARITY_THRESHOLD:
                        matched_row = context_kb.iloc[best_indices_in_context[i]]
                        logs_df.loc[warning_indices[i], 'final_problem_id'] = matched_row['problem_id']
                        logs_df.loc[warning_indices[i], 'final_anomaly_id'] = matched_row['anomaly_id']
    
    # =========================================================================
    # Ð­Ð¢ÐÐŸ 3: Ð“Ð›ÐžÐ‘ÐÐ›Ð¬ÐÐÐ¯ ÐšÐ›ÐÐ¡Ð¡Ð˜Ð¤Ð˜ÐšÐÐ¦Ð˜Ð¯ "ÐžÐ¡Ð˜Ð ÐžÐ¢Ð•Ð’Ð¨Ð˜Ð¥" WARNING-Ð›ÐžÐ“ÐžÐ’
    # =========================================================================
    
    # ÐÐ°Ñ…Ð¾Ð´Ð¸Ð¼ WARNING, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ð½Ðµ Ð±Ñ‹Ð»Ð¸ ÐºÐ»Ð°ÑÑÐ¸Ñ„Ð¸Ñ†Ð¸Ñ€Ð¾Ð²Ð°Ð½Ñ‹ Ð½Ð° ÑÑ‚Ð°Ð¿Ðµ 2
    orphan_mask = (logs_df['Level'] == 'WARNING') & (logs_df['final_problem_id'] == 0)
    
    if orphan_mask.any():
        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³Ð¸ Ð´Ð»Ñ Ð½ÐµÐºÐ»Ð°ÑÑÐ¸Ñ„Ð¸Ñ†Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ñ… WARNING
        orphan_embeddings = model.encode(
            logs_df.loc[orphan_mask, 'Generalized_Message'].tolist(),
            convert_to_tensor=True
        )
        
        # Ð¡Ð¾Ð¿Ð¾ÑÑ‚Ð°Ð²Ð»ÑÐµÐ¼ ÑÐ¾ Ð’Ð¡Ð•Ð™ Ð±Ð°Ð·Ð¾Ð¹ Ð°Ð½Ð¾Ð¼Ð°Ð»Ð¸Ð¹ (Ð±ÐµÐ· ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð½Ð¾Ð¹ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð°Ñ†Ð¸Ð¸)
        best_indices, scores = find_best_match_sbert_batch(
            orphan_embeddings, 
            anomalies_kb_embeddings
        )
        
        if len(best_indices) > 0:
            orphan_indices = logs_df.index[orphan_mask]
            
            # ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ ÐºÐ°Ð¶Ð´Ñ‹Ð¹ "Ð¾ÑÐ¸Ñ€Ð¾Ñ‚ÐµÐ²ÑˆÐ¸Ð¹" WARNING
            for i in range(len(orphan_indices)):
                # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ Ð¾Ñ†ÐµÐ½ÐºÑƒ ÑÑ…Ð¾Ð¶ÐµÑÑ‚Ð¸ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ ÐµÑÐ»Ð¸ Ð½Ð¾Ð²Ð°Ñ Ð²Ñ‹ÑˆÐµ
                if scores[i] > logs_df.loc[orphan_indices[i], 'match_score']:
                    logs_df.loc[orphan_indices[i], 'match_score'] = scores[i]
                
                # Ð•ÑÐ»Ð¸ ÑÑ…Ð¾Ð¶ÐµÑÑ‚ÑŒ Ð²Ñ‹ÑˆÐµ Ð¿Ð¾Ñ€Ð¾Ð³Ð°, ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ ÐºÐ»Ð°ÑÑÐ¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸ÑŽ
                if scores[i] >= WARNING_SIMILARITY_THRESHOLD:
                    matched_row = anomalies_kb.iloc[best_indices[i]]
                    logs_df.loc[orphan_indices[i], 'final_problem_id'] = matched_row['problem_id']
                    logs_df.loc[orphan_indices[i], 'final_anomaly_id'] = matched_row['anomaly_id']
    
    return logs_df

